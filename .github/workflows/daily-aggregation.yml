name: Daily Host Aggregation

on:
  schedule:
    # Run daily at 2:00 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    outputs:
      timestamped_filename: ${{ steps.find-csv.outputs.timestamped_filename }}
          
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch all history for all branches

    - name: Install dependencies
      run: |
        sudo apt-get update && sudo apt-get install -y python3 python3-pip
        python3 -m pip install --upgrade pip
        pip3 install -r requirements.txt
    
    - name: Run host aggregation script
      run: |
        python3 host_aggregator.py
    
    - name: Find generated CSV files
      id: find-csv
      run: |
        # Find the timestamped CSV file (most recent)
        TIMESTAMPED_FILE=$(find data/ -name "host_entries_*.csv" -type f | sort -r | head -n 1)
        LATEST_FILE="data/latest.csv"
        
        if [ -z "$TIMESTAMPED_FILE" ]; then
          echo "Error: No timestamped CSV file found"
          exit 1
        fi
        
        if [ ! -f "$LATEST_FILE" ]; then
          echo "Error: latest.csv file not found"
          exit 1
        fi
        
        # Extract filename without path
        TIMESTAMPED_FILENAME=$(basename "$TIMESTAMPED_FILE")
        
        echo "timestamped_file=$TIMESTAMPED_FILE" >> $GITHUB_OUTPUT
        echo "timestamped_filename=$TIMESTAMPED_FILENAME" >> $GITHUB_OUTPUT
        echo "latest_file=$LATEST_FILE" >> $GITHUB_OUTPUT
        
        echo "Found timestamped file: $TIMESTAMPED_FILE"
        echo "Found latest file: $LATEST_FILE"
        
    - name: Commit generated CSV files to hosts branch
      run: |
        BRANCH_NAME="hosts"
        
        # Checkout hosts branch to commit changes to it
        git checkout $BRANCH_NAME
        
        # Create data/csv directory if it doesn't exist
        mkdir -p data/csv
        
        # Create data/json directory if it doesn't exist
        mkdir -p data/json

        # Copy CSV files to data/csv directory
        cp ${{ steps.find-csv.outputs.latest_file }} data/csv/latest.csv
        cp ${{ steps.find-csv.outputs.timestamped_file }} data/csv/${{ steps.find-csv.outputs.timestamped_filename }}
        
        # Configure git user
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        # Add files to git
        git add .
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # Commit the changes
          git commit -m "Update CSV files: ${{ steps.find-csv.outputs.timestamped_filename }}"
          
          # Push to hosts branch
          git push origin $BRANCH_NAME
          echo "Committed and pushed CSV files to hosts branch"
        fi
        
        # Switch back to main branch for subsequent steps
        git checkout main
    
    - name: Prepare Pages deployment
      # This step runs automatically via GitHub Actions (not locally)
      # It prepares the CSV files for GitHub Pages deployment
      run: |
        # Checkout hosts branch to get the committed CSV files
        git checkout hosts
        
        # Create build directory structure
        mkdir -p build
        
        # Copy entire data/ directory from hosts branch to build directory
        cp -r data build/
        
        echo "Prepared files for GitHub Pages deployment from hosts branch"
    
    - name: Upload Pages artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: './build'
    
  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    permissions:
      pages: write
      id-token: write
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Display completion information
        run: |
          {
            echo "## Host Aggregation Complete"
            echo ""
            echo "### CSV Files Generated:"
            echo "- **Latest CSV**: \`data/csv/latest.csv\`"
            echo "- **Timestamped CSV**: \`data/csv/${{ needs.build.outputs.timestamped_filename }}\`"
            echo ""
            echo "### GitHub Pages URLs:"
            echo "- **Latest CSV**: \`${{ steps.deployment.outputs.page_url }}data/csv/latest.csv\`"
            echo "- **Timestamped CSV**: \`${{ steps.deployment.outputs.page_url }}data/csv/${{ needs.build.outputs.timestamped_filename }}\`"
            echo ""
            echo "Files have been deployed to GitHub Pages and are now accessible."
          } >> $GITHUB_STEP_SUMMARY