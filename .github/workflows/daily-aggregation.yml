name: Daily Host Aggregation

on:
  schedule:
    # Run daily at 2:00 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    outputs:
      timestamped_filename: ${{ steps.find-files.outputs.timestamped_csv_filename }}
          
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch all history for all branches

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run host aggregation script
      run: |
        python host_aggregator.py
    
    - name: Find generated files
      id: find-files
      run: |
        # Define formats to check
        FORMATS=("csv" "json" "yaml")
        
        # Find and validate files for each format
        for FORMAT in "${FORMATS[@]}"; do
          TIMESTAMPED_FILE=$(find data/ -name "host_entries_*.${FORMAT}" -type f | sort -r | head -n 1)
          LATEST_FILE="data/latest.${FORMAT}"
          
          # Validate timestamped file
          if [ -z "$TIMESTAMPED_FILE" ]; then
            echo "Error: No timestamped ${FORMAT^^} file found"
            exit 1
          fi
          
          # Validate latest file
          if [ ! -f "$LATEST_FILE" ]; then
            echo "Error: latest.${FORMAT} file not found"
            exit 1
          fi
          
          # Extract filename without path
          TIMESTAMPED_FILENAME=$(basename "$TIMESTAMPED_FILE")
          
          # Set output variables
          echo "timestamped_${FORMAT}=$TIMESTAMPED_FILE" >> $GITHUB_OUTPUT
          echo "timestamped_${FORMAT}_filename=$TIMESTAMPED_FILENAME" >> $GITHUB_OUTPUT
          echo "latest_${FORMAT}=$LATEST_FILE" >> $GITHUB_OUTPUT
          
          # Log found files
          echo "Found timestamped ${FORMAT^^}: $TIMESTAMPED_FILE"
          echo "Found latest ${FORMAT^^}: $LATEST_FILE"
        done
        
    - name: Commit generated files to hosts branch
      run: |
        BRANCH_NAME="hosts"
        
        # Checkout hosts branch to commit changes to it
        git checkout $BRANCH_NAME
        
        # Create data directories for all formats
        mkdir -p data/{csv,json,yaml}
        
        # Move files to their respective directories
        mv ${{ steps.find-files.outputs.latest_csv }} data/csv/latest.csv
        mv ${{ steps.find-files.outputs.timestamped_csv }} data/csv/${{ steps.find-files.outputs.timestamped_csv_filename }}
        mv ${{ steps.find-files.outputs.latest_json }} data/json/latest.json
        mv ${{ steps.find-files.outputs.timestamped_json }} data/json/${{ steps.find-files.outputs.timestamped_json_filename }}
        mv ${{ steps.find-files.outputs.latest_yaml }} data/yaml/latest.yaml
        mv ${{ steps.find-files.outputs.timestamped_yaml }} data/yaml/${{ steps.find-files.outputs.timestamped_yaml_filename }}
                
        # Configure git user
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        # Add files from data directories
        git add data/csv/ data/json/ data/yaml/
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # Commit the changes
          git commit -m "Update files: ${{ steps.find-files.outputs.timestamped_csv_filename }}"
          
          # Push to hosts branch
          git push origin $BRANCH_NAME
          echo "Committed and pushed files to hosts branch"
        fi
        
        # Switch back to main branch for subsequent steps
        git checkout main
    
    - name: Prepare Pages deployment
      run: |
        # Checkout hosts branch to get the committed files
        git checkout hosts
        
        # Create build directory and copy data directory
        mkdir -p build
        cp -r data build/
        
        echo "Prepared files for GitHub Pages deployment from hosts branch"
    
    - name: Upload Pages artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: './build'
    
  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    permissions:
      pages: write
      id-token: write
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Display completion information
        run: |
          BASE_URL="${{ steps.deployment.outputs.page_url }}"
          TIMESTAMP_BASE="${{ needs.build.outputs.timestamped_filename }}"
          {
            echo "## Host Aggregation Complete"
            echo ""
            echo "### Files Generated:"
            echo "- **CSV**: \`data/csv/latest.csv\`, \`data/csv/${TIMESTAMP_BASE}\`"
            echo "- **JSON**: \`data/json/latest.json\`, \`data/json/${TIMESTAMP_BASE%.csv}.json\`"
            echo "- **YAML**: \`data/yaml/latest.yaml\`, \`data/yaml/${TIMESTAMP_BASE%.csv}.yaml\`"
            echo ""
            echo "### GitHub Pages URLs:"
            echo "- **Latest CSV**: \`${BASE_URL}data/csv/latest.csv\`"
            echo "- **Latest JSON**: \`${BASE_URL}data/json/latest.json\`"
            echo "- **Latest YAML**: \`${BASE_URL}data/yaml/latest.yaml\`"
            echo ""
            echo "Files have been deployed to GitHub Pages and are now accessible."
          } >> $GITHUB_STEP_SUMMARY